Visualization_Homework
================

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
    ## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
    ## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
    ## ✔ tidyr   1.2.0      ✔ stringr 1.4.1 
    ## ✔ readr   2.1.2      ✔ forcats 0.5.2 
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()

``` r
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

#### Load in data

There are 1384617 observations of 15 variables in total. It contains
order details from instacart such as order id, user id, order hour,
product name, product department e.t.c . There are 39123 distinct
products, 131209 order id and 131209 users id in the table.

``` r
library(p8105.datasets)
data("instacart")
```

``` r
instacart %>% 
  count(product_name)
```

    ## # A tibble: 39,123 × 2
    ##    product_name                                                                n
    ##    <chr>                                                                   <int>
    ##  1 "\\\"Constant Comment\\\" Black Tea"                                        3
    ##  2 "\\\"Constant Comment\\\" Decaffeinated Black Tea Blend"                    3
    ##  3 "\\\"Darn Good\\\" Chili Mix"                                               5
    ##  4 "\\\"Im Pei-nut Butter\\\" Double Chocolate Cookie & Peanut Butter Ice…     5
    ##  5 "\\\"Mies Vanilla Rohe\\\" Ice Cream Bars"                                  6
    ##  6 "\\\"Mokaccino\\\" Milk + Blue Bottle Coffee Chocolate"                    10
    ##  7 "& Go! Hazelnut Spread + Pretzel Sticks"                                   10
    ##  8 "#2 Coffee Filters"                                                        22
    ##  9 "#2 Cone White Coffee Filters"                                              1
    ## 10 "#2 Mechanical Pencils"                                                     1
    ## # … with 39,113 more rows

``` r
instacart %>% 
  count(user_id)
```

    ## # A tibble: 131,209 × 2
    ##    user_id     n
    ##      <int> <int>
    ##  1       1    11
    ##  2       2    31
    ##  3       5     9
    ##  4       7     9
    ##  5       8    18
    ##  6       9    22
    ##  7      10     4
    ##  8      13     5
    ##  9      14    11
    ## 10      17     6
    ## # … with 131,199 more rows

``` r
instacart %>% 
  count(order_id)
```

    ## # A tibble: 131,209 × 2
    ##    order_id     n
    ##       <int> <int>
    ##  1        1     8
    ##  2       36     8
    ##  3       38     9
    ##  4       96     7
    ##  5       98    49
    ##  6      112    11
    ##  7      170    17
    ##  8      218     5
    ##  9      226    13
    ## 10      349    11
    ## # … with 131,199 more rows

#### Number of aisles and most popular aisles.

There are 134 aisles. The top three popular aisles are fresh vegetables,
fresh fruits, packaged vegetables fruits.

``` r
instacart %>% 
  group_by(aisle) %>%
  summarize(n_obs = n()) %>% 
  arrange(desc(n_obs))
```

    ## # A tibble: 134 × 2
    ##    aisle                          n_obs
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # … with 124 more rows

#### Plot showing the number of items ordered in each aisle

``` r
instacart %>% 
  group_by(aisle_id, aisle) %>%
  summarize(n_obs = n()) %>% 
  filter(n_obs > 10000) %>%
  ggplot(aes(x = aisle_id, y = n_obs, color = aisle)) +
  geom_point() +
  labs(
    title = "Aisles v.s Order number",
    x = "Aisle_id",
    y = "Number of items ordered"
  ) 
```

    ## `summarise()` has grouped output by 'aisle_id'. You can override using the
    ## `.groups` argument.

<img src="p8105_hw3_yl5221_files/figure-gfm/unnamed-chunk-4-1.png" width="90%" />

#### Table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.

``` r
instacart %>% 
  group_by(aisle, product_name) %>% 
  summarize(n_obs = n()) %>% 
  filter(aisle == "baking ingredients" | aisle =="dog food care" |aisle == "packaged vegetables fruits") %>% 
  mutate(rank = min_rank(desc(n_obs))) %>% 
  filter(rank < 4)
```

    ## `summarise()` has grouped output by 'aisle'. You can override using the
    ## `.groups` argument.

    ## # A tibble: 9 × 4
    ## # Groups:   aisle [3]
    ##   aisle                      product_name                            n_obs  rank
    ##   <chr>                      <chr>                                   <int> <int>
    ## 1 baking ingredients         Cane Sugar                                336     3
    ## 2 baking ingredients         Light Brown Sugar                         499     1
    ## 3 baking ingredients         Pure Baking Soda                          387     2
    ## 4 dog food care              Organix Chicken & Brown Rice Recipe        28     2
    ## 5 dog food care              Small Dog Biscuits                         26     3
    ## 6 dog food care              Snack Sticks Chicken & Rice Recipe Dog…    30     1
    ## 7 packaged vegetables fruits Organic Baby Spinach                     9784     1
    ## 8 packaged vegetables fruits Organic Blueberries                      4966     3
    ## 9 packaged vegetables fruits Organic Raspberries                      5546     2

#### Table showing mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day

``` r
instacart %>% 
    mutate(order_hour_of_day= as.integer(order_hour_of_day)) %>% 
    select(product_name, order_dow, order_hour_of_day) %>% 
    filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
    group_by(product_name, order_dow) %>% 
    summarize(mean_order = mean(order_hour_of_day)) %>% 
    pivot_wider(
    names_from = order_dow,
    values_from = mean_order) 
```

    ## `summarise()` has grouped output by 'product_name'. You can override using the
    ## `.groups` argument.

    ## # A tibble: 2 × 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

## Problem 2

I cleaned the column names, created a column indicating “weekday” and
“weekend”, and perform pivot longer to “activity.” columns. Now I have 6
colunms - “week”, “day”, “day_id”, “day_of_week”, “hour”, “counts”.
There’s 50400 observations of 6 variables.

``` r
accel_df =
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(day_of_week = ifelse(day == "Saturday", "weekend", ifelse(day == "Sunday", "weekend", "weekday"))) %>% 
  pivot_longer(
    starts_with("activity"),
    names_to = "minute",
    values_to = "counts"
  ) %>% 
  separate(minute, into = c("activity", "minute"), sep = "_") %>% 
  select(-activity) %>% 
  mutate(minute = as.numeric(minute))
```

    ## Rows: 35 Columns: 1443
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### Total activity variable for each day

For week 1,2. There’s increasing trend of summation of activity counts
from Monday to Sunday.

``` r
accel_df %>% 
  group_by(week, day) %>% 
  summarize(sum = sum(counts)) %>% 
  arrange(week, sum)
```

    ## `summarise()` has grouped output by 'week'. You can override using the
    ## `.groups` argument.

    ## # A tibble: 35 × 3
    ## # Groups:   week [5]
    ##     week day           sum
    ##    <dbl> <chr>       <dbl>
    ##  1     1 Monday     78828.
    ##  2     1 Tuesday   307094.
    ##  3     1 Wednesday 340115.
    ##  4     1 Thursday  355924.
    ##  5     1 Saturday  376254 
    ##  6     1 Friday    480543.
    ##  7     1 Sunday    631105 
    ##  8     2 Monday    295431 
    ##  9     2 Sunday    422018 
    ## 10     2 Tuesday   423245 
    ## # … with 25 more rows

#### Graph presenting activity counts for each day

Trends of graph: Most of Wednesday’s and Tuesday’s activity counts are
low compared to counts on other days. There’s also trend of low activity
counts between 10pm to 6am, during sleep time. And there’s high activity
counts in the morning and afternoon.

``` r
accel_df %>% 
  ggplot(aes(x = minute, y = counts, color = day)) +
  geom_point(alpha = 0.5) +
    labs(
    title = "Minute v.s Activity Counts",
    x = "Minute",
    y = "Counts of Activity",
    caption = "Data from the accel dataset"
  ) +
  scale_x_discrete(
    breaks = c(0, 360, 720, 1080, 1440),
    labels = c("12AM", "6AM", "12PM", "6PM", "11:59PM"),
    limits = c(0, 1440)
  )
```

    ## Warning: Continuous limits supplied to discrete scale.
    ## Did you mean `limits = factor(...)` or `scale_*_continuous()`?

<img src="p8105_hw3_yl5221_files/figure-gfm/unnamed-chunk-9-1.png" width="90%" />

## Problem 3

#### Data load in and description

This data set contains 2595176 observations of 7 variables.

*id: Weather station ID *date: Date of observation *prcp: Precipitation
(tenths of mm) *snow: Snowfall (mm) *snwd: Snow depth (mm) *tmax:
Maximum temperature (tenths of degrees C) \*tmin: Minimum temperature
(tenths of degrees C)

There’s a lack of data in some weather stations in the table. We have
most missing values on tmin and tmax. For tmax and tmin, missing values
are around 44% of all data. We have a little loss in precipitation, 15%
loss for snowfall, and 23% for snow depth data.

``` r
library(p8105.datasets)
data("ny_noaa")
```

``` r
ny_noaa %>% 
 summarize(
  missing_prcp = mean(is.na(prcp)),
  missing_snow = mean(is.na(snow)),
  missing_snwd = mean(is.na(snwd)),
  missing_tmax = mean(is.na(tmax)),
  missing_tmin = mean(is.na(tmin))
) %>% 
  knitr::kable()
```

| missing_prcp | missing_snow | missing_snwd | missing_tmax | missing_tmin |
|-------------:|-------------:|-------------:|-------------:|-------------:|
|    0.0561958 |     0.146896 |    0.2280331 |    0.4371025 |    0.4371264 |

#### Data cleaning

``` r
ny_noaa =
  ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(
    prcp = prcp/10,
    tmax = as.numeric(tmax)/10, 
    tmin = as.numeric(tmin)/10) 
```

The most common snowfall amount is 0. Because in NY state, there’s no
snow on most days.

``` r
ny_noaa %>% 
  count(snow) %>% 
  arrange(desc(n))
```

    ## # A tibble: 282 × 2
    ##     snow       n
    ##    <int>   <int>
    ##  1     0 2008508
    ##  2    NA  381221
    ##  3    25   31022
    ##  4    13   23095
    ##  5    51   18274
    ##  6    76   10173
    ##  7     8    9962
    ##  8     5    9748
    ##  9    38    9197
    ## 10     3    8790
    ## # … with 272 more rows

#### Average max temperature in January and in July in each station across years plot

The average max temperature in Jan is between -10°C to 10°C. There’s
some outliers when max temperature in Jan drops below -10°C. The average
max temperature in Jul is between 20°C and 35°C. There’s some outliers
when max temperature in Jul falls between 10°C to 20°C.

``` r
ny_noaa %>% 
  filter(month == "01" | month == "07") %>% 
  group_by(id, year, month) %>% 
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax, color = month)) +
  geom_point(alpha = .2) +
  geom_smooth(alpha = .5) +
  labs(
    title = "mean_tmax in Jan and Jul across years",
    x = "Station id",
    y = "temp(°C)",
    caption = "Data from the noaa dataset"
  ) +
  scale_x_discrete(
    breaks = c(1980, 1985, 1990, 1995, 2000, 2005, 2010)
    ) +
  facet_grid(~month) 
```

    ## `summarise()` has grouped output by 'id', 'year'. You can override using the
    ## `.groups` argument.
    ## `geom_smooth()` using method = 'loess' and formula 'y ~ x'

    ## Warning: Removed 5970 rows containing non-finite values (stat_smooth).

    ## Warning: Removed 5970 rows containing missing values (geom_point).

<img src="p8105_hw3_yl5221_files/figure-gfm/unnamed-chunk-14-1.png" width="90%" />

#### tmax vs tmin and distribution of snowfall values

``` r
tmax_tmin_plot =
ny_noaa %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_hex() +
  geom_smooth() +
  labs(
    title = "tmin v.s tmax",
    x = "Min temp(°C)",
    y = "Max temp(°C)",
    caption = "Data from the noaa dataset"
  )
```

``` r
snowfall_plot =
  ny_noaa %>% 
  filter(snow > 0, snow < 100) %>% 
  ggplot(aes(x = snow, y = factor(year), fill = stat(x))) +
  ggridges::geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01, alpha = 0.5) +
  labs(
    title = "NY Snowfall Amount",
    x = "Snowfall(mm)",
    y = "year"
  ) 
```

``` r
tmax_tmin_plot + snowfall_plot
```

    ## Warning: Removed 1136276 rows containing non-finite values (stat_binhex).

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

    ## Warning: Removed 1136276 rows containing non-finite values (stat_smooth).

    ## Picking joint bandwidth of 3.76

<img src="p8105_hw3_yl5221_files/figure-gfm/unnamed-chunk-17-1.png" width="90%" />
