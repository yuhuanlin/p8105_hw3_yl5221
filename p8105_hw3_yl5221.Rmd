---
title: "Visualization_Homework"
output: github_document
---

```{r setup, echo=TRUE, results='hide'}
library(tidyverse)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

#### Load in data 
There are 1384617 observations of 15 variables in total. It contains order details from instacart such as order id, user id, order hour, product name, product department e.t.c . There are 39123 distinct products, 131209 order id and 131209 users id in the table. 
```{r}
library(p8105.datasets)
data("instacart")
```

```{r}
instacart %>% 
  count(product_name)

instacart %>% 
  count(user_id)

instacart %>% 
  count(order_id)
```

#### Number of aisles and most popular aisles.

There are 134 aisles. The top three popular aisles are fresh vegetables, fresh fruits, packaged vegetables fruits.
```{r}
instacart %>% 
  group_by(aisle) %>%
  summarize(n_obs = n()) %>% 
  arrange(desc(n_obs))
```

#### Plot showing the number of items ordered in each aisle
```{r}
instacart %>% 
  group_by(aisle_id, aisle) %>%
  summarize(n_obs = n()) %>% 
  filter(n_obs > 10000) %>%
  ggplot(aes(x = aisle_id, y = n_obs, color = aisle)) +
  geom_point() +
  labs(
    title = "Aisles v.s Order number",
    x = "Aisle_id",
    y = "Number of items ordered"
  ) 
```


#### Table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. 

```{r}
instacart %>% 
  group_by(aisle, product_name) %>% 
  summarize(n_obs = n()) %>% 
  filter(aisle == "baking ingredients" | aisle =="dog food care" |aisle == "packaged vegetables fruits") %>% 
  mutate(rank = min_rank(desc(n_obs))) %>% 
  filter(rank < 4)
```

#### Table showing mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day
```{r}
instacart %>% 
    mutate(order_hour_of_day= as.integer(order_hour_of_day)) %>% 
    select(product_name, order_dow, order_hour_of_day) %>% 
    filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
    group_by(product_name, order_dow) %>% 
    summarize(mean_order = mean(order_hour_of_day)) %>% 
    pivot_wider(
    names_from = order_dow,
    values_from = mean_order) 
```

## Problem 2

I cleaned the column names, created a column indicating "weekday" and "weekend", and perform pivot longer to "activity." columns. Now I have 6 colunms - "week", "day", "day_id", "day_of_week", "hour", "counts". There's 50400 observations of 6 variables. 
```{r}
accel_df =
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(day_of_week = ifelse(day == "Saturday", "weekend", ifelse(day == "Sunday", "weekend", "weekday"))) %>% 
  pivot_longer(
    starts_with("activity"),
    names_to = "minute",
    values_to = "counts"
  ) %>% 
  separate(minute, into = c("activity", "minute"), sep = "_") %>% 
  select(-activity) %>% 
  mutate(minute = as.numeric(minute))
```

#### Total activity variable for each day

For week 1,2. There's increasing trend of summation of activity counts from Monday to Sunday.

```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarize(sum = sum(counts)) %>% 
  arrange(week, sum)
```
 
#### Graph presenting activity counts for each day 
Trends of graph: Most of Wednesday's and Tuesday's activity counts are low compared to counts on other days. There's also trend of low activity counts between 10pm to 6am, during sleep time. And there's high activity counts in the morning and afternoon.
```{r}
accel_df %>% 
  ggplot(aes(x = minute, y = counts, color = day)) +
  geom_point(alpha = 0.5) +
    labs(
    title = "Minute v.s Activity Counts",
    x = "Minute",
    y = "Counts of Activity",
    caption = "Data from the accel dataset"
  ) +
  scale_x_discrete(
    breaks = c(0, 360, 720, 1080, 1440),
    labels = c("12AM", "6AM", "12PM", "6PM", "11:59PM"),
    limits = c(0, 1440)
  )
```


## Problem 3

#### Data load in and description
This data set contains 2595176 observations of 7 variables. 

*id: Weather station ID
*date: Date of observation
*prcp: Precipitation (tenths of mm)
*snow: Snowfall (mm)
*snwd: Snow depth (mm)
*tmax: Maximum temperature (tenths of degrees C)
*tmin: Minimum temperature (tenths of degrees C)

There's a lack of data in some weather stations in the table. We have most missing values on tmin and tmax. For tmax and tmin, missing values are around 44% of all data. We have a little loss in precipitation, 15% loss for snowfall, and 23% for snow depth data.

```{r}
library(p8105.datasets)
data("ny_noaa")
```

```{r}
ny_noaa %>% 
 summarize(
  missing_prcp = mean(is.na(prcp)),
  missing_snow = mean(is.na(snow)),
  missing_snwd = mean(is.na(snwd)),
  missing_tmax = mean(is.na(tmax)),
  missing_tmin = mean(is.na(tmin))
) %>% 
  knitr::kable()
```

#### Data cleaning
```{r}
ny_noaa =
  ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(
    prcp = prcp/10,
    tmax = as.numeric(tmax)/10, 
    tmin = as.numeric(tmin)/10) 
```

The most common snowfall amount is 0. Because in NY state, there's no snow on most days.
```{r}
ny_noaa %>% 
  count(snow) %>% 
  arrange(desc(n))
```

#### Average max temperature in January and in July in each station across years plot
The average max temperature in Jan is between -10°C to 10°C. There's some outliers when max temperature in Jan drops below -10°C. The average max temperature in Jul is between 20°C and 35°C. There's some outliers when max temperature in Jul falls between 10°C to 20°C.
```{r}
ny_noaa %>% 
  filter(month == "01" | month == "07") %>% 
  group_by(id, year, month) %>% 
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax, color = month)) +
  geom_point(alpha = .2) +
  geom_smooth(alpha = .5) +
  labs(
    title = "mean_tmax in Jan and Jul across years",
    x = "Station id",
    y = "temp(°C)",
    caption = "Data from the noaa dataset"
  ) +
  scale_x_discrete(
    breaks = c(1980, 1985, 1990, 1995, 2000, 2005, 2010)
    ) +
  facet_grid(~month) 
```


#### tmax vs tmin and distribution of snowfall values
```{r}
tmax_tmin_plot =
ny_noaa %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_hex() +
  geom_smooth() +
  labs(
    title = "tmin v.s tmax",
    x = "Min temp(°C)",
    y = "Max temp(°C)",
    caption = "Data from the noaa dataset"
  )
```


```{r}
snowfall_plot =
  ny_noaa %>% 
  filter(snow > 0, snow < 100) %>% 
  ggplot(aes(x = snow, y = factor(year), fill = stat(x))) +
  ggridges::geom_density_ridges_gradient(scale = 3, rel_min_height = 0.01, alpha = 0.5) +
  labs(
    title = "NY Snowfall Amount",
    x = "Snowfall(mm)",
    y = "year"
  ) 
```

```{r}
tmax_tmin_plot + snowfall_plot
```


